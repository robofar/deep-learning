{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759e03cc-1a7d-4e43-bc57-c6b8bed09714",
   "metadata": {},
   "source": [
    "# Assignment 3 - Transfer Learning ; Data Augumentation ; Popular CNN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51cc32c-06e0-4413-8317-e2b18b37fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110d57e-2c6c-4845-914f-0e0a1e854f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02caa90d-bd9d-4207-b76b-871be2da309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a607c-c924-4991-8149-3cf6fbd67d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1aa41-d40f-41c2-9370-445bc415b577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75e08687-e5d0-4ade-8cb0-e46d8e620d0c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e214b-2d57-4964-a0a7-3a5ba0a52985",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d48d25-3166-48b2-ae2d-fd2ab1c4e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.StanfordCars(root='./data', split='train', transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.StanfordCars(root='./data', split='test', transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ddbd80-33c2-4bd5-9e64-314c5d286878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd048cc-ebb7-465a-ad07-04d46bd60316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bb6f6-e8fa-4fc7-804f-03f2a7048e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b92afd-d484-41f1-af4f-f6fe971ad1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a87034e-92c5-40dd-aa96-564d3205fbc2",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd90129-e20a-4501-a77b-3345f31a6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting data loaders for iterating\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff2200-5770-48ed-a6cb-38ab73b63ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_loader)\n",
    "current_batch = next(it)\n",
    "print(current_batch[0].shape) # batch x\n",
    "print(len(current_batch[1])) # batch y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33fdc9-360a-4d9d-bb51-a266b90cb16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65174e08-bb57-4830-9e24-85aff4a9233c",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c249e-5310-4a94-a171-fb65994e5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMGS = 4\n",
    "fig, ax = plt.subplots(1, N_IMGS)\n",
    "fig.set_size_inches(4 * N_IMGS, 4)\n",
    "\n",
    "#cifar10_labels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "ids = np.random.randint(low=0, high=len(train_dataset), size=N_IMGS)\n",
    "\n",
    "for i, n in enumerate(ids):\n",
    "    #img = train_dataset[n][0].numpy().transpose(1, 2, 0) => also can be called like this (instead of this down)\n",
    "    img = train_dataset[n][0].permute(1, 2, 0)\n",
    "    label_idx = train_dataset[n][1]\n",
    "    #label_name = cifar10_labels[label_idx]\n",
    "    \n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(f\"Img #{n}  Label INdex: {label_idx}\")\n",
    "    ax[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84b126-9ecb-46f4-97f5-4d3ea3df4718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52f0a414-fb11-41e4-8fc9-aabe622450ff",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5abfbd-4c7b-4695-a16d-72987f6cdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\" Training a model for one epoch \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_list = []\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "         \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += len( torch.where(preds==labels)[0] )\n",
    "        total += len(labels)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Total correct predictions and loss\n",
    "    accuracy = correct / total * 100\n",
    "    mean_loss = np.mean(loss_list)\n",
    "    \n",
    "    return accuracy, mean_loss, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca611c-5b81-40fa-a311-efa31d120982",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model_epoch(model, eval_loader, criterion, device):\n",
    "    \"\"\" Evaluating the model for either validation or test \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_list = []\n",
    "    \n",
    "    for images, labels in eval_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "                 \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "            \n",
    "        # Get predictions from the maximum value\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += len( torch.where(preds==labels)[0] )\n",
    "        total += len(labels)\n",
    "                 \n",
    "    # Total correct predictions and loss\n",
    "    accuracy = correct / total * 100\n",
    "    mean_loss = np.mean(loss_list)\n",
    "    \n",
    "    return accuracy, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536f0a2-9099-4d1a-b316-7020b1c33535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, criterion, train_loader, valid_loader, num_epochs, tboard=None, start_epoch=0):\n",
    "    \"\"\" Training a model for a given number of epochs\"\"\"\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss =  []\n",
    "    loss_iters = []\n",
    "    valid_acc = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "           \n",
    "        # validation epoch\n",
    "        model.eval()  # important for dropout and batch norms\n",
    "        accuracy, loss = eval_model(\n",
    "                    model=model, eval_loader=valid_loader,\n",
    "                    criterion=criterion, device=device\n",
    "            )\n",
    "        valid_acc.append(accuracy)\n",
    "        val_loss.append(loss)\n",
    "        writer.add_scalar(f'Accuracy/Valid', accuracy, global_step=epoch+start_epoch)\n",
    "        writer.add_scalar(f'Loss/Valid', loss, global_step=epoch+start_epoch)\n",
    "        \n",
    "        # training epoch\n",
    "        model.train()  # important for dropout and batch norms\n",
    "        mean_loss, cur_loss_iters = train_epoch(\n",
    "                model=model, train_loader=train_loader, optimizer=optimizer,\n",
    "                criterion=criterion, device=device\n",
    "            )\n",
    "        scheduler.step()\n",
    "        train_loss.append(mean_loss)\n",
    "        writer.add_scalar(f'Loss/Train', mean_loss, global_step=epoch+start_epoch)\n",
    "\n",
    "        loss_iters = loss_iters + cur_loss_iters\n",
    "        \n",
    "        if(epoch % 5 == 0 or epoch==num_epochs-1):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"    Train loss: {round(mean_loss, 5)}\")\n",
    "            print(f\"    Valid loss: {round(loss, 5)}\")\n",
    "            print(f\"    Accuracy: {accuracy}%\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    print(f\"Training completed\")\n",
    "    return train_loss, val_loss, loss_iters, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ce1ac-ce77-4b67-b2e1-f8999ae07321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, stats):\n",
    "    \"\"\" Saving model checkpoint \"\"\"\n",
    "    \n",
    "    if(not os.path.exists(\"models\")):\n",
    "        os.makedirs(\"models\")\n",
    "    savepath = f\"models/checkpoint_epoch_{epoch}.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'stats': stats\n",
    "    }, savepath)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171dbf46-a1cf-4842-99b6-5fe46dc146f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, optimizer, savepath):\n",
    "    \"\"\" Loading pretrained checkpoint \"\"\"\n",
    "    \n",
    "    checkpoint = torch.load(savepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    stats = checkpoint[\"stats\"]\n",
    "    \n",
    "    return model, optimizer, epoch, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52667a-978f-4e9a-bc4f-e63a527f4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed=None):\n",
    "    \"\"\"\n",
    "    Using random seed for numpy and torch\n",
    "    \"\"\"\n",
    "    if(random_seed is None):\n",
    "        random_seed = 13\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91806ba1-01c1-47d0-8c04-16fb33481367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aed80d-8607-4fe3-994e-462c5229b349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903e351-6a21-4ae0-945b-f34e56b0805b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b60848d2-45e6-4f16-b686-82e1bdcf92ad",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d306662-e324-42e1-9491-23418a45b674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef2d26-f407-49e8-9e35-816f8012f5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd02d86c-b2a0-44c8-8d2c-56e222a7a21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbd328-b418-4cb9-aca5-7d26f06ad4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab011a0-4198-4964-95ee-ad728cdf078d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e1398-4a29-4522-a276-2f7f39b99a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba90b1-e5ed-4c7f-a980-8691569bf9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb10abb-4283-4546-ab84-250ed13be60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82710610-accb-4d7c-945f-549f73df3ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56fc5bb7-442b-4525-a969-e6382139dc2f",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e74e5-6981-480b-bf11-48529374c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(24,5)\n",
    "\n",
    "ax[0].plot(loss_iters, c=\"blue\", label=\"Loss\", linewidth=3, alpha=0.5)\n",
    "ax[0].legend(loc=\"best\")\n",
    "ax[0].set_xlabel(\"Iteration\")\n",
    "ax[0].set_ylabel(\"CE Loss\")\n",
    "ax[0].set_title(\"Training Progress\")\n",
    "\n",
    "epochs = np.arange(len(train_loss)) + 1\n",
    "ax[1].plot(epochs, train_loss, c=\"red\", label=\"Train Loss\", linewidth=3)\n",
    "ax[1].plot(epochs, val_loss, c=\"blue\", label=\"Valid Loss\", linewidth=3)\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"CE Loss\")\n",
    "ax[1].set_title(\"Loss Curves\")\n",
    "\n",
    "epochs = np.arange(len(val_loss)) + 1\n",
    "ax[2].plot(epochs, valid_acc, c=\"red\", label=\"Valid accuracy\", linewidth=3)\n",
    "ax[2].legend(loc=\"best\")\n",
    "ax[2].set_xlabel(\"Epochs\")\n",
    "ax[2].set_ylabel(\"Accuracy (%)\")\n",
    "ax[2].set_title(f\"Valdiation Accuracy (max={round(np.max(valid_acc),2)}% @ epoch {np.argmax(valid_acc)+1})\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad5ec7-5bbd-401a-b664-2404b18a7916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b7c69-d0bb-417c-a9d5-c5ad72b0b309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8500c-a11b-41c9-8af3-9b0a87f316e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afcf55-06c8-4be5-8f51-bb9144b7eec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
